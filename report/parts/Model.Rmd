```{r}
library(ggplot2)
library(dplyr)
library(readr)
library(tidyr)
library(nnet)
library(glmnet)
library(car)
library(themis)
library(pROC)
library(reshape2)
library(MASS)
```

```{r}
test <- read_csv('../data/testset.csv')
```

```{r}
train_base <- read_csv('../data/training_sets/train_base.csv')
train_under <- read_csv('../data/training_sets/train_under.csv')
train_over <- read_csv('../data/training_sets/train_over.csv')
train_combine <- read_csv('../data/training_sets/train_combine.csv')
train_smote <- read_csv('../data/training_sets/train_smote.csv')
```

```{r}
eval_multi_class <- function(x) {
    cc <- sum(diag(x), na.rm = TRUE)
    sc <- sum(x)
    pp <- colSums(x)
    tt <- rowSums(x)
    
    prec <- diag(x) / colSums(x)
    recall <- diag(x) / rowSums(x)
    macro_prec <- mean(prec, na.rm = TRUE)
    macro_recall <- mean(recall, na.rm = TRUE)
    macro_f1 <- 2 * macro_prec * macro_recall / (macro_prec + macro_recall)
    acc <- cc / sc
    
    denominator <- (sc^2 - sum(pp * tt))
    if (denominator != 0) {
        kap <- (as.numeric(cc) * as.numeric(sc) - sum(pp * tt)) / denominator
    } else {
        kap <- NA
    }
    
    return(list(Precision = prec, Recall = recall, Accuracy = acc, Kappa = kap, Macro_F1 = macro_f1))
}
```

#### Model với tất cả các biến

```{r}
first_models <- list()

for (i in 1:4) {
    if (i == 1) {
        df <- train_under
    } else if (i == 2) {
        df <- train_over
    } else if (i == 3) {
        df <- train_combine
    } else {
        df <- train_smote
    }
    
    model <- multinom(Diabetes_012 ~ ., data = df, maxit = 1000)
    pred_class <- predict(model, test, type = 'class')
    
    cm <- table(test$Diabetes_012, pred_class)
    eval <- eval_multi_class(cm)
    
    first_models[[i]] <- list(Model = model, Prediction_Class = pred_class, Confusion_Matrix = cm, Evaluation = eval)
}

```

```{r}
# lấy ra Residual Deviance và AIC của mỗi model
for (i in 1:4) {
    if (i == 1) {
        print('Under Sampling')
    } else if (i == 2) {
        print('Over Sampling')
    } else if (i == 3) {
        print('Combine Sampling')
    } else {
        print('SMOTE')
    }
    print(first_models[[i]]$Model$deviance)
    print(first_models[[i]]$Model$AIC)
}
```

Các thông số đánh giá cho mỗi model với tập train khác nhau cho kết quả khác nhau do số lượng quan trắc trong mỗi tập dữ liệu train. Do đó chưa thể đánh giá được model với tập dữ liệu nào tốt hơn, nhưng nhìn chung các chỉ số này lớn và gợi ý là có nhiều vấn đề với model trên tập dữ liệu. 

```{r}
# tìm outlier dựa trên residuals của model_combine
model_combine <- first_models[[3]]$Model
residuals <- residuals(model_combine, type = 'deviance')
outliers <- which(abs(residuals) > 3)
outliers 
```

```{r}
# lấy ra các evalution của từng model
evaluations <- lapply(first_models, function(x) x$Evaluation)

for (i in 1:4) {
    if (i == 1) {
        cat('Undersampling\n')
    } else if (i == 2) {
        cat('Oversampling\n')
    } else if (i == 3) {
        cat('Combine\n')
    } else {
        cat('SMOTE\n')
    }
    
    print(evaluations[[i]])
    cat('\n')
}
```

```{r}
# vẽ trực quan confusion matrix của từng model
sampling_methods <- c("Undersampling", "Oversampling", "Combine", "SMOTE")

for (i in 1:4) {    
    cm <- first_models[[i]]$Confusion_Matrix
    cm_melt <- melt(cm)
    colnames(cm_melt) <- c("Var1", "Var2", "value")
    p <- ggplot(data = cm_melt, aes(x = Var2, y = Var1, fill = value)) +
        geom_tile() +
        geom_text(aes(label = value), color = "black") +
        scale_fill_gradient(low = "white", high = "blue") +
        labs(x = "Predicted", y = "Actual", fill = "Count") +
        ggtitle(paste("Confusion Matrix -", sampling_methods[i])) +
        theme_minimal()

    print(p)
}
```

Nhận thấy model chạy với train_combine có vẻ cho kết quả tốt nhất trong phân loại nhóm 1 và 2.

Tiếp theo, ta sử dụng công cụ tự động lựa chọn biến để xem model tốt nhất giữ lại những biến nào. 

### Stepwise

```{r}
full_model <- multinom(Diabetes_012 ~ ., data = train_combine, maxit = 1500)

stepwise_model <- stepAIC(full_model, direction = "both", trace = TRUE)
```

```{r}
summary(stepwise_model)
```

model sau stepwise vẫn giữ lại toàn bộ biến.

```{r}
vif(stepwise_model)
```

có đa cộng tuyến trong mô hình. 

```{r}
prop_pred <- predict(stepwise_model, test, type = 'class')
conf_matrix <- table(test$Diabetes_012, prop_pred)
print(eval_multi_class(conf_matrix))
```

```{r}
cm_melt <- melt(conf_matrix)
colnames(cm_melt) <- c("Var1", "Var2", "value")
ggplot(data = cm_melt, aes(x = Var2, y = Var1, fill = value)) +
    geom_tile() +
    geom_text(aes(label = value), color = "black") +
    scale_fill_gradient(low = "white", high = "blue") +
    labs(x = "Predicted", y = "Actual", fill = "Count") +
    ggtitle("Confusion Matrix - Combine") +
    theme_minimal()
```

do phát hiện có đa cộng tuyến, mô hình sẽ gặp vấn đề hệ số ước lượng không ổn định nên ta sử dụng phương pháp co hệ số để giảm ảnh hưởng này. 

### Regularization

```{r}
# xài glmnet 
model_lasso <- glmnet(as.matrix(train_combine[, -1]), as.factor(train_combine$Diabetes_012), family = 'multinomial', alpha = 1)
model_ridge <- glmnet(as.matrix(train_combine[, -1]), as.factor(train_combine$Diabetes_012), family = 'multinomial', alpha = 0)
model_enet <- glmnet(as.matrix(train_combine[, -1]), as.factor(train_combine$Diabetes_012), family = 'multinomial', alpha = 0.5)
```

```{r}
# Predict and evaluate for Lasso model
pred_lasso <- predict(model_lasso, newx = as.matrix(test[, -1]), s = 0.01, type = 'class')
cm_lasso <- table(test$Diabetes_012, pred_lasso)
cat("Confusion Matrix for Lasso Model:\n")
print(eval_multi_class(cm_lasso))

# Predict and evaluate for Ridge model
pred_ridge <- predict(model_ridge, newx = as.matrix(test[, -1]), s = 0.01, type = 'class')
cm_ridge <- table(test$Diabetes_012, pred_ridge)
cat("\nConfusion Matrix for Ridge Model:\n")
print(eval_multi_class(cm_ridge))

# Predict and evaluate for Elastic Net model
pred_enet <- predict(model_enet, newx = as.matrix(test[, -1]), s = 0.01, type = 'class')
cm_enet <- table(test$Diabetes_012, pred_enet)
cat("\nConfusion Matrix for Elastic Net Model:\n")
print(eval_multi_class(cm_enet))
```

```{r}
# Predict and evaluate for Ridge model on train 
pred_ridge <- predict(model_ridge, newx = as.matrix(train_combine[, -1]), s = 0.01, type = 'class')
cm_ridge <- table(train_combine$Diabetes_012, pred_ridge)
cat("\nConfusion Matrix for Ridge Model on Train set:\n")
print(eval_multi_class(cm_ridge))
```

Model với ridge cho kết quả tốt nhất và cũng khá gần với kết quả có được với stepwise_model.

Kết quả sau khi xây dựng mô hình tuyến tính có vẻ chưa quá khả quan trong phân loại, ta có thể nghi ngờ về quan hệ phi tuyến của các biến. Để kiểm tra thử, ta sẽ sử dụng mô hình phi tuyến là Random Forest.

### Random Forest

```{r}
library(randomForest)
```

```{r}
train_combine$Diabetes_012 <- as.factor(train_combine$Diabetes_012)
set.seed(12)
rf_model <- randomForest(Diabetes_012 ~ ., data = train_combine, ntree = 100, maxnodes = 6, importance = TRUE)
```

```{r}
# evaluation trên tập train
pred_rf_train <- predict(rf_model, train_combine, type = 'class')
cm_rf_train <- table(train_combine$Diabetes_012, pred_rf_train)
cat("\nConfusion Matrix for Random Forest Model on Train Set:\n")
print(eval_multi_class(cm_rf_train))
```

```{r}
# evaluation trên tập test 
pred_rf <- predict(rf_model, test, type = 'class')
cm_rf <- table(test$Diabetes_012, pred_rf)
cat("\nConfusion Matrix for Random Forest Model:\n")
print(eval_multi_class(cm_rf))
```

### Kết luận

Mặc dù model Random Forest cho recall của class 2 khá cao, tuy nhiên recall cho class 1 lại gần như bằng 0. Nếu tuning các tham số cho model thì recall cho 2 class này sẽ tương quan nghịch với nhau, nếu recall class này cao thì buộc class kia phải giảm. 

Hơn nữa, macro_F1 cũng chỉ đạt 0.45, cũng tương đương với model logistic đã xây dựng ở trên. *Điều này cho thấy cả 2 model tuyến tính và phi tuyến đều không hoạt động tốt trên tập dữ liệu*.

**Kết luận:** Có thể vấn đề nằm ở bộ dữ liệu được cung cấp không có đủ thông tin để dự đoán biến mục tiêu hoặc có chứa thông tin nhiễu. Nhất là đối với class 1, khi dữ liệu trong nhóm này rất ít so với 2 class còn lại nên việc dự đoán nhóm này rất khó dù đã có các biện pháp xử lí mất cân bằng. 

**Giải pháp:** 
1. Thu thập thêm dữ liệu những người bị tiền tiểu đường (class 1). 
2. Chuyển qua phân loại nhị phân, dự đoán 1 người bị tiểu đường hoặc không. (loại bỏ hết các quan trắc thuộc class 1 hoặc gom nhãn class 1 và 2). 

Do tính chất về mức độ bệnh và phương pháp điều trị cho người tiểu đường và tiền tiểu đường là khác nhau nên việc chuyển hướng sang phân loại nhị phân có thể không giải thích được hết vấn đề đặt ra.      
Theo khảo sát dân cư ở Mỹ thì số lượng người tiền tiểu đường nhiều hơn số lượng người tiểu đường nên việc dự đoán tiền tiểu đường cũng rất cần thiết. 