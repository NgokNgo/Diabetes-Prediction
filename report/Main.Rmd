```{r}
library(ggplot2)
library(dplyr)
library(readr)
library(tidyr)
library(reshape2)
library(corrplot)
library(nnet)
library(glmnet)
library(car)
library(themis)
library(pROC)
library(MASS)
```

```{r}
df <- read_csv('../../data/diabetes_012_health_indicators_BRFSS2015.csv')
head(df)
```

## Exploratory Data Analysis (EDA)

```{r}
str(df)
```

```{r}
# check for missing values
sum(is.na(df))
```

dữ liệu không có NaN

```{r}
# Check for duplicated rows
sum(duplicated(df))
```

dữ liệu có ~24000 dòng bị trùng nhau, chiếm khoảng 9.5% dữ liệu gốc     
tuy nhiên dữ liệu không có id cho mỗi observation nên có thể xem mỗi observation là 1 cá thể riêng biệt và có thể có dữ liệu về tình trạng sức khỏe giống nhau. => có thể không cần thực hiện xóa dữ liệu trùng lặp

```{r}
# Count unique values in each column
print(sapply(df, n_distinct))
```

hầu hết các biến trong dataset là biến nhị phân -> biến định tính       
các biến định tính không phải nhị phân bao gồm: Diabetes_012, GenHlth, Age, Education, Income       
các biến định lượng:  
- rời rạc: MentHlth, PhysHlth
- liên tục: BMI (trong dataset này thì được biểu diễn rời rạc)

### Phân phối của các biến

#### Biến định lượng

Vẽ biểu đồ phân phối và boxplot. 

```{r}
# Plot histograms for quantitative variables
par(mfrow=c(3,1), bg='white')
hist(df$MentHlth, breaks=31, col='green', main='MentHlth Histogram')
hist(df$PhysHlth, breaks=31, col='blue', main='PhysHlth Histogram')
hist(df$BMI, breaks=84, col='red', main='BMI Histogram')
```

MentHlth và PhysHlth chứa nhiều giá trị 0: phần lớn mọi người không có vấn đề về sức khỏe tinh thần và thể chất. 
Histogram cho 2 biến này đương tối tương đồng -> có thể có tương quan/ đa cộng tuyến giữa 2 biến này.       

Phân phối của cả 3 biến đang bị lệch phải. 

```{r}
options(repr.plot.width=10, repr.plot.height=5)

ggplot(df, aes(x = factor(0), y = MentHlth, fill= factor(0))) + 
    geom_boxplot() + 
    labs(title = "MenHlth Boxplot") + 
    theme_minimal() + 
    coord_flip()

ggplot(df, aes(x = factor(0), y = PhysHlth, fill= factor(0))) + 
    geom_boxplot() + 
    labs(title = "PhysHlth Boxplot") + 
    theme_minimal() + 
    coord_flip()
```

đa phần quan sát gặp vấn đề về tinh thần và thể chất kéo dài < 10 ngày. Số ít (outlier) kéo dài >= 10 ngày.

```{r}
ggplot(df, aes(x = factor(0), y = BMI, fill= factor(0))) + 
    geom_boxplot() + 
    labs(title = "BMI Boxplot") + 
    theme_minimal() + 
    coord_flip()
```

```{r}
# summary for BMI
summary(df$BMI)
```

thông qua boxplot và bảng summary thì ta thấy rõ hơn được phân bố của BMI tập trung chủ yếu vào khoảng [24,31] với trung bình là 28 độ lệch là 6, và có nhiều outlier có BMI lớn.

**Tính tỉ lệ outliers:**

```{r}
percent_outliers <- function(x) {
  sum(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x)) / length(x) * 100
}

print(percent_outliers(df$BMI))
print(percent_outliers(df$MentHlth))
print(percent_outliers(df$PhysHlth))
```

#### Biến định tính

Vẽ biểu đồ tần số.

```{r}
df2 <- df %>% select(-BMI, -MentHlth, -PhysHlth)
df2_melt <- melt(df2)

options(repr.plot.width=10, repr.plot.height=8)

ggplot(df2_melt, aes(x = value, fill = variable)) + 
    geom_bar() + 
    facet_wrap(~variable, scales = 'free_x') + 
    theme_minimal()
```

dữ liệu cân bằng ở các biến (xấp xỉ 40-50%): HighBP, HighChol, Smoker, Sex.     
trên thực tế thì khả năng khảo sát được kết quả này là bình thường          
tỉ lệ sex cân bằng cũng cho thấy dữ liệu khảo sát đều trên cả 2 giới tính

**Dữ liệu mất cân bằng trong biến dự đoán Diabetes_012, cụ thể là tỉ lệ người không bị tiểu đường nhiều >> tỉ lệ người bị tiểu đường và tiền tiểu đường**

Kiểm tra tỉ lệ cho biến dự đoán tiểu đường:

```{r}
# tỉ lệ phần trăm của biến Diabetes_012
tm <- table(
    df$Diabetes_012,
    useNA = 'ifany'
)
prop.table(tm)
```

Ở đây tỉ lệ trong nhóm 0 (Không bị tiểu đường) chiếm đến 84%, trong khi nhóm 1 chiếm chưa tới 2%.       
=> **Dữ liệu bị mất cân bằng nặng.** 

Các biến khác:
- Đa số các quan sát đã kiểm tra cholesterol trong 5 năm, chỉ một số ít chưa kiểm tra.
- Số lượng quan sát từng bị đột quỵ hoặc bị nhồi máu cơ tim thấp.
- Đa số quan sát có hoạt động thể chất trong vòng 30 ngày gần đây, khoảng hơn 1/5 quan sát là không.
- Số người ăn trái cây ít nhất một ngày gần gấp đôi số người không.
- Đa số các quan sát ăn rau củ quả mỗi ngày, chiếm hơn 4/5 toàn bộ quan sát.
- Đa số các quan sát không uống nhiều rượu.
- Đa số các quan sát đã tiếp cận các dịch vụ sức khỏe.
- Một số ít quan sát (khoảng dưới 50.000) không gặp bác sĩ trong vòng 12 tháng vì không có kinh phí.
- Đa số các tình trạng sức khỏe chung của quan sát đều ở mức Very Good (nhãn 2) và Good (nhãn 3).
- Có khoảng gần 50.000 quan sát gặp tình trạng khó khăn trong đi lại.
- Trình độ học vấn quan sát được trong mẫu ở mức 4,5,6 nhiều (6 là cao nhất) => **cân nhắc gộp nhãn hiếm (1,2,3)** 
- Thu nhập ở mức 8 (cao nhất) cũng có số lượng cao nhất và giảm dần ở các mức còn lại. 

```{r}
options(repr.plot.width=10, repr.plot.height=5)

ggplot(df, aes(x = factor(0), y = Age, fill = factor(0))) + 
  geom_boxplot() + 
  labs(title = "Age Boxplot") + 
  theme_minimal() +
  coord_flip()
```

phần lớn các quan sát nằm trong **nhóm** tuổi từ 6-10, với nhóm 1 có độ tuổi từ 18-24, nhóm 2 từ 25-29, nhóm 3 từ 30-34,... thì mẫu này chứa nhiều quan sát trong nhóm tuổi từ 45-69.

**Tổng quan**: Đa số các quan trắc trong dataset này nằm trong độ tuổi trung niên, có thu nhập khá tốt và cũng có lối sống lành mạnh. Qua đó cũng quan sát thấy số lượng các quan trắc không bị bệnh tiểu đường cũng chiếm đa số. 

Các yếu tố được quan sát và khả năng mắc bệnh tiểu đường có thể liên quan với nhau. 

### Correlation

```{r}
correlation <- cor(df, use = 'pairwise.complete.obs')
corrplot(correlation)
```

Một số biến trong dataset có tương quan mạnh với nhau:
- (GenHlth, PhysHlth), (PhysHlth, DiffWalk), (Education, Income), (GenHlth, DiffWalk), (MenthHlth, PhysHlth): tương quan thuận
- (GenHlth, Income), (DiffWalk, Income): tương quan nghịch

Bên cạnh đó thì các biến sau cũng có tương quan với khá nhiều biến khác: GenHlth, PhysHlth, DiffWalk, Income, 

**Tương quan của các biến với biến Diabetes_012:**

```{r}
correlation_with_diabetes <- cor(df)[, "Diabetes_012"]
barplot(correlation_with_diabetes[-which(names(correlation_with_diabetes) == "Diabetes_012")], 
        main = "Correlation with Diabetes_012", col = "orange", las = 2)
```

**Các biến có tương quan nhiều với biến dự đoán:** HighBP, HighChol, BMI, CholCheck, Stroke, HeartDiseaseorAttack, PhysActivity, GenHlth, PhysHlth, DiffWalk, Age, Education, Income.       

### Quan hệ của các biến giải thích với biến dự đoán

#### Biến nhị phân

```{r}
binary_vars <- df %>% select_if(~n_distinct(.) <= 3) %>% mutate(Diabetes_012 = df$Diabetes_012)

options(repr.plot.width=10, repr.plot.height=8)
# Reshape data for plotting
binary_vars_melt <- melt(binary_vars, id.vars = "Diabetes_012")

ggplot(binary_vars_melt, aes(x = value, fill = factor(Diabetes_012))) + 
  geom_bar(position = "dodge") + 
  facet_wrap(~variable, scales = 'free_x') + 
  theme_minimal() + 
  labs(y = "Count", fill = "Diabetes_012")
```

```{r}
df2 <- df %>% select(-BMI, -MentHlth, -PhysHlth, -GenHlth, -Age, -Education, -Income)

results <- list()

for (col in colnames(df2)) {
  if (col != "Diabetes_012") {
    result <- df2 %>%
      group_by(!!sym(col)) %>%
      count(Diabetes_012) %>%
      mutate(percentage = n / sum(n)) %>%
      select(-n) %>%
      spread(Diabetes_012, percentage, fill = 0) %>%
      ungroup()
    
    result <- result %>%
      mutate(Name = paste0(col, "_", !!sym(col))) %>%
      select(Name, `0`, `1`, `2`) %>%
      rename(`No Diabetes` = `0`, `Pre Diabetes` = `1`, `Diabetes` = `2`)
    
    results[[col]] <- result
  }
}

results_df <- bind_rows(results)
results_df <- results_df %>% select(Name, `No Diabetes`, `Pre Diabetes`, `Diabetes`)
head(results_df)
```

```{r}
# chọn các biến có khác biệt tỉ lệ trên 10% 
for (i in seq(1, nrow(results_df), by = 2)) {
  if (abs(results_df[i, 'No Diabetes'] - results_df[i + 1, 'No Diabetes']) > 0.1) {
    print(substr(results_df[i, 'Name'], 1, nchar(as.character(results_df[i, 'Name'])) - 2))
  }
}
```

=> các biến trên có thể có ảnh hưởng **lớn** đến khả năng mắc bệnh tiểu đường.

#### Các biến định tính còn lại
 GenHlth, Age, Education, Income

```{r}
df %>% group_by(GenHlth) %>%
  count(Diabetes_012) %>%
  mutate(percentage = n / sum(n)) %>%
  select(-n) %>%
  spread(Diabetes_012, percentage, fill = 0)
```

```{r}
categorical_vars <- df %>% select(Diabetes_012, GenHlth, Age, Education, Income)

ggplot(categorical_vars, aes(x = GenHlth, fill = factor(Diabetes_012))) + 
  geom_bar(position = "dodge") + 
  theme_minimal() + 
  labs(y = "Proportion", fill = "Diabetes_012", title = "Relation between GenHlth and Diabetes")

```

Các trường hợp có sức khỏe Excellent (nhãn 1) và Very Good (nhãn 2) thì ít khả năng mắc bệnh tiểu đường. Ngược lại thì với nhãn 4 và 5 thì xác suất mắc bệnh tiểu đường khá cao. 

```{r}
df %>% group_by(Age) %>%
  count(Diabetes_012) %>%
  mutate(percentage = n / sum(n)) %>%
  select(-n) %>%
  spread(Diabetes_012, percentage, fill = 0)
```

```{r}
ggplot(categorical_vars, aes(x = Age, fill = factor(Diabetes_012))) + 
  geom_bar(position = "dodge") + 
  theme_minimal() + 
  labs(y = "Proportion", fill = "Diabetes_012", title = "Relation between Age and Diabetes")

```

Dữ liệu quan sát được đa số quan trắc nằm trong nhóm tuổi từ 6-10. Khả năng mắc bệnh tiểu đường trong nhóm này tăng dần theo độ tuổi. Khả năng mắc bệnh ở nhóm 11 và 12 không tăng và giảm ở nhóm 13. 

```{r}
df %>% group_by(Education) %>%
  count(Diabetes_012) %>%
  mutate(percentage = n / sum(n)) %>%
  select(-n) %>%
  spread(Diabetes_012, percentage, fill = 0)
```

```{r}
ggplot(categorical_vars, aes(x = Education, fill = factor(Diabetes_012))) + 
  geom_bar(position = "dodge") + 
  theme_minimal() + 
  labs(y = "Proportion", fill = "Diabetes_012", title = "Relation between Education and Diabetes")

```

Khả năng mắc bệnh tiểu đường có xu hướng giảm dần từ nhóm có trình độ học vấn thấp đến trình độ học vấn cao. 

(Số lượng người được khảo sát có trình độ học vấn từ 1->3 ở đây đang rất ít só với các nhóm còn lại nên có thể chưa phản ánh chính xác)

```{r}
df %>% group_by(Income) %>%
  count(Diabetes_012) %>%
  mutate(percentage = n / sum(n)) %>%
  select(-n) %>%
  spread(Diabetes_012, percentage, fill = 0)
```

```{r}
ggplot(categorical_vars, aes(x = Income, fill = factor(Diabetes_012))) + 
  geom_bar(position = "dodge") + 
  theme_minimal() + 
  labs(y = "Proportion", fill = "Diabetes_012", title = "Relation between Income and Diabetes")
```

Khả năng bị bệnh tiểu đường cũng có xu hướng giảm dần từ nhóm có thu nhập thấp đến nhóm có thu nhập cao.

Do đã quan sát thấy Education và Income có tương quan thuận, nên xu hướng cho 2 biến này lên biến phụ thuộc giống nhau. 

#### Biến định lượng
BMI, MentHlth, PhysHlth

```{r}
ggplot(df, aes(x = MentHlth, fill = factor(Diabetes_012))) + 
  geom_histogram(position = "identity", alpha = 0.5, bins = 31) + 
  theme_minimal() + 
  labs(fill = "Diabetes_012", title = "Relation between MentHlth and Diabetes")

```

```{r}
ggplot(df, aes(x = factor(Diabetes_012), y = MentHlth, fill = factor(Diabetes_012))) + 
  geom_boxplot() +
  theme_minimal() + 
  labs(fill = "Diabetes_012", title = "Relation between Diabetes_012 and MentHlth")
```

```{r}
ggplot(df, aes(x = factor(Diabetes_012), y = MentHlth, fill = factor(Diabetes_012))) + 
  geom_violin() +
  theme_minimal() + 
  labs(fill = "Diabetes_012", title = "Relation between Diabetes_012 and MentHlth")
```

phân phối cho MentHlth khá đều trong các trường hợp về bệnh tiểu đường.         
Đa số người không bị tiểu đường thì gặp vấn đề sức khỏe tinh thần kéo dài dưới 5 ngày.          
Những người không gặp vấn đề tâm lí (MentHlth=0) vẫn có khả năng mắc tiểu đường hoặc không, giá trị trung bình cho cả 3 boxplot đều là 0.  

Với biểu đồ violin thì quan sát thấy số người bị tiểu đường có vấn đề sức khỏe tinh thần trong khoảng 30 ngày liên tục nhiều hơn so với nhóm không bị tiểu đường. 

```{r}
ggplot(df, aes(x = PhysHlth, fill = factor(Diabetes_012))) + 
  geom_histogram(position = "identity", alpha = 0.5, bins = 31) + 
  theme_minimal() + 
  labs(fill = "Diabetes_012", title = "Relation between PhysHlth and Diabetes")

```

```{r}
ggplot(df, aes(x = factor(Diabetes_012), y = PhysHlth, fill = factor(Diabetes_012))) + 
  geom_boxplot() + 
  theme_minimal() + 
  labs(fill = "Diabetes_012", title = "Relation between Diabetes_012 and PhysHlth")
```

```{r}
ggplot(df, aes(x = factor(Diabetes_012), y = PhysHlth, fill = factor(Diabetes_012))) + 
  geom_violin() + 
  theme_minimal() + 
  labs(fill = "Diabetes_012", title = "Relation between Diabetes_012 and PhysHlth")
```

phân phối cho PhysHlth đã cho sự chênh lệch nhất định.      
Đa số người không bị tiểu đường cũng gặp vấn đề sức khỏe thể chất < 5 ngày.         
Phân phối của nhóm người tiền tiểu đường trải dài hơn gần như gấp đôi so với MentHlth.          
Phân phối của nhóm người bị tiểu đường trải dài hết vùng giá trị của PhysHlth và không có outliers, trung bình cho nhóm này cũng đã bị kéo lên không còn ở 0. 

```{r}
ggplot(df, aes(x = BMI, fill = factor(Diabetes_012))) + 
  geom_histogram(position = "identity", alpha = 0.5, bins = 84) + 
  theme_minimal() + 
  labs(fill = "Diabetes_012", title = "Relation between BMI and Diabetes")
```

```{r}
df %>% group_by(Diabetes_012) %>%
  summarise(
    mean = mean(BMI, na.rm = TRUE), 
    sd = sd(BMI, na.rm = TRUE),
    Q1 = quantile(BMI, 0.25, na.rm = TRUE),
    Q3 = quantile(BMI, 0.75, na.rm = TRUE))
```

```{r}
ggplot(df, aes(x = factor(Diabetes_012), y = BMI, fill = factor(Diabetes_012))) + 
  geom_boxplot() + 
  theme_minimal() + 
  labs(fill = "Diabetes_012", title = "Relation between Diabetes_012 and BMI")
```

```{r}
ggplot(df, aes(x = factor(Diabetes_012), y = BMI, fill = factor(Diabetes_012))) + 
  geom_violin() + 
  theme_minimal() + 
  labs(fill = "Diabetes_012", title = "Relation between Diabetes_012 and BMI")
```

Những người bị tiền tiểu đường/ tiểu đường có trung bình BMI cao hơn những người không bị tiểu đường. 

đa số người bị tiểu đường hoặc tiền tiểu đường nằm trong khoảng BMI từ [26,35] 

### Quan hệ tương tác của các biến giải thích với biến dự đoán

Kiểm tra các biến có tương quan mạnh với nhau:
- (GenHlth, PhysHlth), (PhysHlth, DiffWalk), (Education, Income), (GenHlth, DiffWalk), (MenthHlth, PhysHlth): tương quan thuận
- (GenHlth, Income), (DiffWalk, Income): tương quan nghịch

#### Định tính với định tính

```{r}
par(bg = 'white')
mosaicplot(table(df$Education, df$Income), main = "Mosaic plot for Education and Income", color = TRUE, shade = TRUE)
```

```{r}
par(bg = 'white')
mosaicplot(table(df$GenHlth, df$DiffWalk), main = "Mosaic plot for GenHlth and DiffWalk", color = TRUE, shade = TRUE)
```

```{r}
par(bg = 'white')
mosaicplot(table(df$GenHlth, df$Income), main = "Mosaic plot for GenHlth and Income", color = TRUE, shade = TRUE)
```

```{r}
par(bg = 'white')
mosaicplot(table(df$DiffWalk, df$Income), main = "Mosaic plot for DiffWalk and Income", color = TRUE, shade = TRUE)
```

các ô màu đậm xuất hiện nhiều -> giá trị thực tế khác biệt với giá trị kỳ vọng -> có tương quan giữa 2 biến 

=> Các biểu đồ trên đều cho thấy có sự tương quan giữa 2 biến được xét

#### Định tính với định lượng

```{r}
# ve boxplot cho PhysHlth voi GenHlth
ggplot(df, aes(x = factor(GenHlth), y = PhysHlth, fill = factor(GenHlth))) + 
  geom_boxplot() + 
  theme_minimal() + 
  labs(fill = "GenHlth", title = "Relation between GenHlth and PhysHlth")
```

=> Phần lớn người có GenHlth đạt mức 1 thì không gặp vấn đề sức khỏe thể chất, GenHlth ở các mức tệ hơn thì có gặp vấn đề sức khỏe thể chất kéo dài, đặc biệt là GenHlth ở mức xấu nhất thì phần lớn mọi người gặp vấn đề thể chất kéo dài suốt 30 ngày (trung bình của boxplot ở 30). 

```{r}
# ve boxplot cho PhysHlth voi DiffWalk
ggplot(df, aes(x = factor(DiffWalk), y = PhysHlth, fill = factor(DiffWalk))) + 
  geom_boxplot() + 
  theme_minimal() + 
  labs(fill = "DiffWalk", title = "Relation between DiffWalk and PhysHlth")
```

=> Những người có vấn đề với việc đi lại cũng sẽ gặp vấn đề về thể chất. 

#### Định lượng với định lượng

```{r}
ggplot(df, aes(x = MentHlth, y = PhysHlth, color = factor(Diabetes_012))) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) + 
  theme_minimal() + 
  labs(color = "Diabetes_012", title = "Relation between MentHlth and PhysHlth")
```

=> Những người gặp vấn đề về sức khỏe tinh thần kéo dài thì cũng có khả năng gặp vấn đề về sức khỏe thể chất kéo dài.       
Trung bình số ngày gặp vấn đề sức khỏe của nhóm không tiểu đường thì thấp hơn so với nhóm tiền tiểu đường và tiểu đường.

### Kết luận sơ bộ sau khi khám phá dữ liệu

1 số biến có tương quan với nhau => có thể dẫn đến đa cộng tuyến => có thể ảnh hưởng đến logistic regression        

**Preprocessing:**       
Dữ liệu về số lượng người mắc bệnh tiểu đường và không mắc bệnh bị mất cân bằng nặng => xử lí imbalanced data.         
Các biến định lượng có chứa outliers => có thể dùng log transform/ robust scaling hoặc chia lại nhãn. 
- có thể chia nhãn dữ liệu lại: **Education**.
- có thể dùng Robust Scaling cho: **BMI, MentHlth và PhysHlth**.

*Không loại bỏ outliers được vì outliers của BMI có ý nghĩa trong dự đoán tiểu đường, outliers của MentHlth và PhysHlth thì > 10%.*

**Hypothesis Testing:** Các loại kiểm định có thể áp dụng với bộ dữ liệu:            
1. Kiểm định **Chi-square** giữa các biến định tính.
2. Kiểm định **ANOVA/ Kruskal-Wallis** giữa biến định lượng và định tính/ định lượng.

**Mục tiêu:** Dự đoán/Phân loại 1 người vào 1 trong 3 class: tiểu đường, tiền tiểu đường, không bị bệnh tiểu đường.            
Biến dự đoán: Diabetes_012.             
*Do dữ liệu mất cân bằng nên ưu tiên dự đoán người có khả năng tiền tiểu đường hoặc tiểu đường và chấp nhận các trường hợp dương tính giả.* 

## Data Cleaning / Preprocessing Data

### Outliers

gom nhóm nhãn hiếm cho Education.       
1: Less than high school.       
2: High School.     
3: College.     
4: College gradute. 

```{r}
df <- df %>%
  mutate(Education = case_when(
    Education %in% c(1,2,3) ~ 1,
    Education %in% c(4,5,6) ~ Education
  )) %>%
  mutate(Education = factor(Education, levels = c(1,4,5,6), labels = c(1,2,3,4)))

df$Education <- as.double(as.character(df$Education))
```

```{r}
ggplot(df, aes(x=as.factor(Education), fill=Education)) +
    geom_bar() +
    labs(title = "Education Distribution",
         x = "Education Level",
         y = "Count") +
    theme_minimal() 
```

Scale lại dữ liệu cho các biến định lượng để giảm ảnh hưởng của outliers. 

```{r}
robust_scaler <- function(x) {
  Q1 <- quantile(x, 0.25) 
  Q3 <- quantile(x, 0.75) 
  IQR <- Q3 - Q1          
  median_x <- median(x)   

  scaled_x <- (x - median_x) / IQR
  return(scaled_x)
}

df <- df %>%
  mutate(BMI = robust_scaler(BMI)) %>%
  mutate(PhysHlth = robust_scaler(PhysHlth)) %>%
  mutate(MentHlth = robust_scaler(MentHlth))
```

```{r}
# plot the distribution of BMI, PhysHlth, and MentHlth
par(mfrow=c(3,1), bg='white')
hist(df$MentHlth, breaks=31, col='green', main='MentHlth Histogram')
hist(df$PhysHlth, breaks=31, col='blue', main='PhysHlth Histogram')
hist(df$BMI, breaks=84, col='red', main='BMI Histogram')
```

```{r}
write.csv(df, '../data/clean_outliers.csv', row.names=FALSE)
```

### Imbalanced 

```{r}
df <- read.csv('../data/clean_outliers.csv')
```

```{r}
# split the data into training and testing sets
set.seed(345)
train_index <- sample(1:nrow(df), 0.7*nrow(df))
train <- df[train_index,]
test <- df[-train_index,]
```

```{r}
with(train, table(Diabetes_012))
```

kiểm tra số lượng các quan trắc duy nhất trong nhóm tiền tiểu đường 

```{r}
with(train %>% distinct(), table(Diabetes_012))
```

```{r}
with(test, table(Diabetes_012))
```

```{r}
write.csv(train, '../data/train_set/train_base.csv', row.names=FALSE)
```

```{r}
write.csv(test, '../data/testset.csv', row.names=FALSE)
```

Under Sampling 

```{r}
under_sampling_3c <- function(data, name_class) {
    class_fact <- as.factor(data[, name_class])
    data_split <- split(data, class_fact)
    n_class <- sapply(data_split, FUN = nrow)
    n_minor <- min(n_class)
    
    new_data <- do.call(rbind, lapply(data_split, function(class_data) {
        id_sample <- sample(1:nrow(class_data), size = n_minor, replace = FALSE)
        class_data[id_sample, ]
    }))
    
    return(new_data)
}

```

```{r}
set.seed(345)
train_under <- under_sampling_3c(train, "Diabetes_012")
with(train_under, table(Diabetes_012))
```

```{r}
# save the under-sampled data to csv 
write.csv(train_under, '../data/train_set/train_under.csv', row.names=FALSE)
```

Over Sampling

```{r}
over_sampling_3c <- function(data, name_class) {
    class_fact <- as.factor(data[, name_class])
    data_split <- split(data, class_fact)
    n_class <- sapply(data_split, FUN = nrow)
    n_major <- max(n_class)
    
    new_data <- do.call(rbind, lapply(data_split, function(class_data) {
        id_sample <- sample(1:nrow(class_data), size = n_major, replace = TRUE)
        class_data[id_sample, ]
    }))
    
    return(new_data)
}
```

```{r}
set.seed(345)
train_over <- over_sampling_3c(train, "Diabetes_012")
with(train_over, table(Diabetes_012))
```

```{r}
write.csv(train_over, '../data/train_set/train_over.csv', row.names=FALSE)
```

Under + Over Sampling

```{r}
# kết hợp under sampling và over sampling cho 3 classes
combine_sampling_3c <- function(data, name_class) {
    class_fact <- as.factor(data[, name_class])
    data_split <- split(data, class_fact)
    n_class <- sapply(data_split, FUN = nrow)
    
    # xác định cỡ mẫu chung cho các class (avg)
    n_avg <- round(mean(n_class))

    new_data <- do.call(rbind, lapply(data_split, function(class_data) {
        n_class_data <- nrow(class_data)
        if (n_class_data < n_avg) {
            id_sample <- sample(1:n_class_data, size = n_avg - n_class_data, replace = TRUE)
            class_data <- rbind(class_data, class_data[id_sample, ])
        } else {
            id_sample <- sample(1:n_class_data, size = n_avg, replace = FALSE)
            class_data <- class_data[id_sample, ]
        }
        return(class_data)
    }))
    
    return(new_data)
}
```

```{r}
set.seed(345)
train_combine <- combine_sampling_3c(train, "Diabetes_012")
with(train_combine, table(Diabetes_012))
```

```{r}
write.csv(train_combine, '../data/train_set/train_combine.csv', row.names=FALSE)
```

SMOTE

```{r}
library(themis)
```

```{r}
train$Diabetes_012 <- as.factor(train$Diabetes_012)
set.seed(345)
train_smote <- smotenc(df= train, var = "Diabetes_012", k = 5, over_ratio = 1)
```

```{r}
with(train_smote, table(Diabetes_012))
```

```{r}
write.csv(train_smote, '../data/train_set/train_smote.csv', row.names=FALSE)
```

## Hypothesis Testing 

```{r}
df <- read_csv('../data/clean_outliers.csv')
```

```{r}
# kiểm định chi-square với monte carlo simulation
chisq_test <- function(df, var1, var2) {
  observed <- table(df[[var1]], df[[var2]])
  chisq <- chisq.test(observed, simulate.p.value = TRUE, B = 10000)
  return(chisq)
}
```

```{r}
# kiểm định kruskal-wallis
kruskal_test <- function(df, var1, var2) {
  kruskal <- kruskal.test(df[[var1]] ~ df[[var2]], data = df)
  return(kruskal)
}
```

### Biến giải thích với predictor

```{r}
df_category <- df %>% select(-c('BMI', 'MentHlth', 'PhysHlth', 'Diabetes_012'))

# lấy tên tất cả các cột trong df_category
vars <- colnames(df_category)

chi_square_results <- data.frame(variable = character(), p_value = numeric(), reject = logical(), stringsAsFactors = FALSE)

for (var in vars) {
    chi_square <- chisq_test(df, 'Diabetes_012', var)
    reject <- chi_square$p.value < 0.05
    chi_square_results <- rbind(chi_square_results, data.frame(variable = var, p_value = chi_square$p.value, reject = reject))
}

chi_square_results

```

```{r}
vars_quantitative <- c('BMI', 'PhysHlth', 'MentHlth')

for (var in vars_quantitative) {
   results <- aov(formula=df[[var]] ~ df[['Diabetes_012']], data = df)
   print(summary(results))
}
```

```{r}
for (var in vars_quantitative) {
   results <- kruskal_test(df, var, 'Diabetes_012')
   print(results)
}
```

### Biến giải thích với nhau

```{r}
df_category <- df %>% select(-BMI, -PhysHlth, -MentHlth)

# chuyển Diabetes_012 xuống cuối cùng
df_category <- df_category %>% select(-Diabetes_012, Diabetes_012)

chi_square_results <- data.frame(variable1 = character(), 
                                variable2 = character(), 
                                No_Diabetes = numeric(),
                                Pre_Diabetes = numeric(),
                                Diabetes = numeric(),
                                reject = logical(), 
                                stringsAsFactors = FALSE)

for (i in 1:(ncol(df_category)-1)) {
    for (j in (i+1):(ncol(df_category)-1)) {
        if (i != j && i != ncol(df_category)-1 && j != ncol(df_category)-1) {
            var1 <- colnames(df_category)[i]
            var2 <- colnames(df_category)[j]
            observes <- table(df_category[[var1]], df_category[[var2]], df_category$Diabetes_012)

            no_diabetes <- chisq.test(observes[,,1],simulate.p.value = TRUE, B = 5000)
            pre_diabetes <- chisq.test(observes[,,2],simulate.p.value = TRUE, B = 5000)
            diabetes <- chisq.test(observes[,,3],simulate.p.value = TRUE, B = 5000)
            if (no_diabetes$p.value < 0.05 && pre_diabetes$p.value < 0.05 && diabetes$p.value < 0.05) {
                reject <- TRUE
            } else {
                reject <- FALSE
            }  

            chi_square_results <- rbind(chi_square_results, data.frame(variable1 = var1, 
                                                                    variable2 = var2, 
                                                                    No_Diabetes = no_diabetes$p.value,
                                                                    Pre_Diabetes = pre_diabetes$p.value,
                                                                    Diabetes = diabetes$p.value, 
                                                                    reject = reject))
        }
    }
}
chi_square_results %>% filter(reject == TRUE)
```

```{r}

chi_square_results %>% filter(reject == FALSE)
```

```{r}
# kruskal-wallis results
kruskal_wallis_results <- data.frame(variable1 = character(), 
                                     variable2 = character(), 
                                     No_Diabetes = numeric(),
                                     Pre_Diabetes = numeric(),
                                     Diabetes = numeric(),
                                     reject = logical(), 
                                     stringsAsFactors = FALSE)

for (var1 in vars_quantitative) {
    for (var2 in vars_quantitative) {
        if (var1 != var2) {
            no_diabetes <- kruskal_test(df %>% filter(Diabetes_012 == 0), var1, var2)
            pre_diabetes <- kruskal_test(df %>% filter(Diabetes_012 == 1), var1, var2)
            diabetes <- kruskal_test(df %>% filter(Diabetes_012 == 2), var1, var2)
            
            if (no_diabetes$p.value < 0.05 && pre_diabetes$p.value < 0.05 && diabetes$p.value < 0.05) {
                reject <- TRUE
            } else {
                reject <- FALSE
            }  

            kruskal_wallis_results <- rbind(kruskal_wallis_results, data.frame(variable1 = var1, 
                                                                              variable2 = var2, 
                                                                              No_Diabetes = no_diabetes$p.value,
                                                                              Pre_Diabetes = pre_diabetes$p.value,
                                                                              Diabetes = diabetes$p.value, 
                                                                              reject = reject))
        }
    }
}

```

```{r}
kruskal_wallis_results
```

### Kết luận

Sau quá trình kiểm định quan hệ giữa các biến, ta có được các nhận xét:
- Tất cả các biến giải thích đều có đóng góp vào mô hình.
- Đa số các biến giải thích có mối quan hệ tương quan, điều này làm mô hình khả năng rất cao bị đa cộng tuyến. 
Tuy nhiên nếu loại bỏ hết đa cộng tuyến thì giảm hiệu suất mô hình do mâu thuẫn với nhận xét 1. 

## Models 

```{r}
test <- read_csv('../data/testset.csv')
```

```{r}
train_base <- read_csv('../data/training_sets/train_base.csv')
train_under <- read_csv('../data/training_sets/train_under.csv')
train_over <- read_csv('../data/training_sets/train_over.csv')
train_combine <- read_csv('../data/training_sets/train_combine.csv')
train_smote <- read_csv('../data/training_sets/train_smote.csv')
```

```{r}
eval_multi_class <- function(x) {
    cc <- sum(diag(x), na.rm = TRUE)
    sc <- sum(x)
    pp <- colSums(x)
    tt <- rowSums(x)
    
    prec <- diag(x) / colSums(x)
    recall <- diag(x) / rowSums(x)
    macro_prec <- mean(prec, na.rm = TRUE)
    macro_recall <- mean(recall, na.rm = TRUE)
    macro_f1 <- 2 * macro_prec * macro_recall / (macro_prec + macro_recall)
    acc <- cc / sc
    
    denominator <- (sc^2 - sum(pp * tt))
    if (denominator != 0) {
        kap <- (as.numeric(cc) * as.numeric(sc) - sum(pp * tt)) / denominator
    } else {
        kap <- NA
    }
    
    return(list(Precision = prec, Recall = recall, Accuracy = acc, Kappa = kap, Macro_F1 = macro_f1))
}
```

### Model với tất cả các biến

```{r}
first_models <- list()

for (i in 1:4) {
    if (i == 1) {
        df <- train_under
    } else if (i == 2) {
        df <- train_over
    } else if (i == 3) {
        df <- train_combine
    } else {
        df <- train_smote
    }
    
    model <- multinom(Diabetes_012 ~ ., data = df, maxit = 1000)
    pred_class <- predict(model, test, type = 'class')
    
    cm <- table(test$Diabetes_012, pred_class)
    eval <- eval_multi_class(cm)
    
    first_models[[i]] <- list(Model = model, Prediction_Class = pred_class, Confusion_Matrix = cm, Evaluation = eval)
}

```

```{r}
# lấy ra Residual Deviance và AIC của mỗi model
for (i in 1:4) {
    if (i == 1) {
        print('Under Sampling')
    } else if (i == 2) {
        print('Over Sampling')
    } else if (i == 3) {
        print('Combine Sampling')
    } else {
        print('SMOTE')
    }
    print(first_models[[i]]$Model$deviance)
    print(first_models[[i]]$Model$AIC)
}
```

Các thông số đánh giá cho mỗi model với tập train khác nhau cho kết quả khác nhau do số lượng quan trắc trong mỗi tập dữ liệu train. Do đó chưa thể đánh giá được model với tập dữ liệu nào tốt hơn, nhưng nhìn chung các chỉ số này lớn và gợi ý là có nhiều vấn đề với model trên tập dữ liệu. 

```{r}
# tìm outlier dựa trên residuals của model_combine
model_combine <- first_models[[3]]$Model
residuals <- residuals(model_combine, type = 'deviance')
outliers <- which(abs(residuals) > 3)
outliers 
```

```{r}
# lấy ra các evalution của từng model
evaluations <- lapply(first_models, function(x) x$Evaluation)

for (i in 1:4) {
    if (i == 1) {
        cat('Undersampling\n')
    } else if (i == 2) {
        cat('Oversampling\n')
    } else if (i == 3) {
        cat('Combine\n')
    } else {
        cat('SMOTE\n')
    }
    
    print(evaluations[[i]])
    cat('\n')
}
```

```{r}
# vẽ trực quan confusion matrix của từng model
sampling_methods <- c("Undersampling", "Oversampling", "Combine", "SMOTE")

for (i in 1:4) {    
    cm <- first_models[[i]]$Confusion_Matrix
    cm_melt <- melt(cm)
    colnames(cm_melt) <- c("Var1", "Var2", "value")
    p <- ggplot(data = cm_melt, aes(x = Var2, y = Var1, fill = value)) +
        geom_tile() +
        geom_text(aes(label = value), color = "black") +
        scale_fill_gradient(low = "white", high = "blue") +
        labs(x = "Predicted", y = "Actual", fill = "Count") +
        ggtitle(paste("Confusion Matrix -", sampling_methods[i])) +
        theme_minimal()

    print(p)
}
```

Nhận thấy model chạy với train_combine có vẻ cho kết quả tốt nhất trong phân loại nhóm 1 và 2.

Tiếp theo, ta sử dụng công cụ tự động lựa chọn biến để xem model tốt nhất giữ lại những biến nào. 

### Stepwise

```{r}
full_model <- multinom(Diabetes_012 ~ ., data = train_combine, maxit = 1500)

stepwise_model <- stepAIC(full_model, direction = "both", trace = TRUE)
```

```{r}
summary(stepwise_model)
```

model sau stepwise vẫn giữ lại toàn bộ biến.

```{r}
vif(stepwise_model)
```

có đa cộng tuyến trong mô hình. 

```{r}
prop_pred <- predict(stepwise_model, test, type = 'class')
conf_matrix <- table(test$Diabetes_012, prop_pred)
print(eval_multi_class(conf_matrix))
```

```{r}
cm_melt <- melt(conf_matrix)
colnames(cm_melt) <- c("Var1", "Var2", "value")
ggplot(data = cm_melt, aes(x = Var2, y = Var1, fill = value)) +
    geom_tile() +
    geom_text(aes(label = value), color = "black") +
    scale_fill_gradient(low = "white", high = "blue") +
    labs(x = "Predicted", y = "Actual", fill = "Count") +
    ggtitle("Confusion Matrix - Combine") +
    theme_minimal()
```

do phát hiện có đa cộng tuyến, mô hình sẽ gặp vấn đề hệ số ước lượng không ổn định nên ta sử dụng phương pháp co hệ số để giảm ảnh hưởng này. 

### Regularization

```{r}
# xài glmnet 
model_lasso <- glmnet(as.matrix(train_combine[, -1]), as.factor(train_combine$Diabetes_012), family = 'multinomial', alpha = 1)
model_ridge <- glmnet(as.matrix(train_combine[, -1]), as.factor(train_combine$Diabetes_012), family = 'multinomial', alpha = 0)
model_enet <- glmnet(as.matrix(train_combine[, -1]), as.factor(train_combine$Diabetes_012), family = 'multinomial', alpha = 0.5)
```

```{r}
# Predict and evaluate for Lasso model
pred_lasso <- predict(model_lasso, newx = as.matrix(test[, -1]), s = 0.01, type = 'class')
cm_lasso <- table(test$Diabetes_012, pred_lasso)
cat("Confusion Matrix for Lasso Model:\n")
print(eval_multi_class(cm_lasso))

# Predict and evaluate for Ridge model
pred_ridge <- predict(model_ridge, newx = as.matrix(test[, -1]), s = 0.01, type = 'class')
cm_ridge <- table(test$Diabetes_012, pred_ridge)
cat("\nConfusion Matrix for Ridge Model:\n")
print(eval_multi_class(cm_ridge))

# Predict and evaluate for Elastic Net model
pred_enet <- predict(model_enet, newx = as.matrix(test[, -1]), s = 0.01, type = 'class')
cm_enet <- table(test$Diabetes_012, pred_enet)
cat("\nConfusion Matrix for Elastic Net Model:\n")
print(eval_multi_class(cm_enet))
```

```{r}
# Predict and evaluate for Ridge model on train 
pred_ridge <- predict(model_ridge, newx = as.matrix(train_combine[, -1]), s = 0.01, type = 'class')
cm_ridge <- table(train_combine$Diabetes_012, pred_ridge)
cat("\nConfusion Matrix for Ridge Model on Train set:\n")
print(eval_multi_class(cm_ridge))
```

Model với ridge cho kết quả tốt nhất và cũng khá gần với kết quả có được với stepwise_model.

Kết quả sau khi xây dựng mô hình tuyến tính có vẻ chưa quá khả quan trong phân loại, ta có thể nghi ngờ về quan hệ phi tuyến của các biến. Để kiểm tra thử, ta sẽ sử dụng mô hình phi tuyến là Random Forest.

### Random Forest

```{r}
library(randomForest)
```

```{r}
train_combine$Diabetes_012 <- as.factor(train_combine$Diabetes_012)
set.seed(12)
rf_model <- randomForest(Diabetes_012 ~ ., data = train_combine, ntree = 100, maxnodes = 6, importance = TRUE)
```

```{r}
# evaluation trên tập train
pred_rf_train <- predict(rf_model, train_combine, type = 'class')
cm_rf_train <- table(train_combine$Diabetes_012, pred_rf_train)
cat("\nConfusion Matrix for Random Forest Model on Train Set:\n")
print(eval_multi_class(cm_rf_train))
```

```{r}
# evaluation trên tập test 
pred_rf <- predict(rf_model, test, type = 'class')
cm_rf <- table(test$Diabetes_012, pred_rf)
cat("\nConfusion Matrix for Random Forest Model:\n")
print(eval_multi_class(cm_rf))
```

### Kết luận

Mặc dù model Random Forest cho recall của class 2 khá cao, tuy nhiên recall cho class 1 lại gần như bằng 0. Nếu tuning các tham số cho model thì recall cho 2 class này sẽ tương quan nghịch với nhau, nếu recall class này cao thì buộc class kia phải giảm. 

Hơn nữa, macro_F1 cũng chỉ đạt 0.45, cũng tương đương với model logistic đã xây dựng ở trên. *Điều này cho thấy cả 2 model tuyến tính và phi tuyến đều không hoạt động tốt trên tập dữ liệu*.

**Kết luận:** Có thể vấn đề nằm ở bộ dữ liệu được cung cấp không có đủ thông tin để dự đoán biến mục tiêu hoặc có chứa thông tin nhiễu. Nhất là đối với class 1, khi dữ liệu trong nhóm này rất ít so với 2 class còn lại nên việc dự đoán nhóm này rất khó dù đã có các biện pháp xử lí mất cân bằng. 

**Giải pháp:** 
1. Thu thập thêm dữ liệu những người bị tiền tiểu đường (class 1). 
2. Chuyển qua phân loại nhị phân, dự đoán 1 người bị tiểu đường hoặc không. (loại bỏ hết các quan trắc thuộc class 1 hoặc gom nhãn class 1 và 2). 

Do tính chất về mức độ bệnh và phương pháp điều trị cho người tiểu đường và tiền tiểu đường là khác nhau nên việc chuyển hướng sang phân loại nhị phân có thể không giải thích được hết vấn đề đặt ra.      
Theo khảo sát dân cư ở Mỹ thì số lượng người tiền tiểu đường nhiều hơn số lượng người tiểu đường nên việc dự đoán tiền tiểu đường cũng rất cần thiết. 